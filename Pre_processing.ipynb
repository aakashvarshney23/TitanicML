{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Disaster\n",
    "\n",
    "Not much information is known about the titanic disaster. This not infamous disaster happened on April 15th, 1912 after the ship collided with an iceberg during her journey. In this project we are going to discover the underlying traits fro the features that enable people to survive the crash. Among the people survived there were kids, women, and men. We also discover what genger, age group survived the most and the underlying reasoning behind it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "Training and Test data have been copied to new variables to avoid the accidental data change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = train.copy()\n",
    "test_e = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Dive and quick look at the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passenger ID doesn't make any difference to the data training. Therefore we plan to drop it. Separating out numerical and cateogorical features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e.drop(columns='PassengerId', axis=1, inplace=True)\n",
    "test_e.drop(columns='PassengerId', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_FEATURES =  ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']  \n",
    "CATEGORICAL_FEATURES = ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
    "TARGET = ['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are five numerical and five categorical features and survived as the target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the data where the target variable has been removed from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_e.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearranging the Columns by moving the target variable to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = train_e[NUMERICAL_FEATURES + CATEGORICAL_FEATURES + TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look on statistics of the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e[NUMERICAL_FEATURES].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_e[NUMERICAL_FEATURES].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick dive into the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e[CATEGORICAL_FEATURES].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings:\n",
    "\n",
    "* There are 891 records in the training data set.\n",
    "* Age has only 714 values out of 891. \n",
    "* The range of age was from toddler to 80 year old. \n",
    "* Majority of the sample was in Pclass 3.\n",
    "* There were a few people beyond the age of 38. \n",
    "* Majority of the family is a small family only a few family had more than one sibling. \n",
    "* Number of parents/children on were mostly 0 only a few family had 6 parents/children. \n",
    "* The fare varied form the range of 0 to $513. Most of the people paid less than 31 dollars.\n",
    "* The names are unique all across, which means no two people had the same name. \n",
    "* There was no ambiguity in entering the data for Sex because there are only two types of values. \n",
    "* Cabin has similar information across many of their enteries this is due to the fact that a ship can have many cabins. \n",
    "* Embarked has 3 values which means that there are three stops from where people embarked. The value 'S' tops the world. \n",
    "* Out of 13 features in the training dataset. We have 6 integer values, 2 float data types, and 5 string data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"There are {} observation and {} columns in training dataset\".format(train_e.shape[0], train_e.shape[1]))\n",
    "print (\"There are {} observation and {} columns in test dataset\".format(test_e.shape[0], test_e.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the missing columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_e.isnull().sum(), columns= ['No. of missing values']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age has 177 missing records wehreas Cabin has 687 missing records which is significant portion of the dataset. Embarked has only 2 missing values which is not that much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_e.isnull().sum(), columns= ['No. of missing values']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age has 86 missing records wehreas Cabin has 327 missing records, which is significant portion of the dataset. This similar kind of pattern was noticed in the training dataset as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family Name \n",
    "Created a new feature Family value to distinguish people who belong to the same family. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e['FamilyName'] = train_e['Name'].str.split(\",\",expand=True)[0]\n",
    "test_e['FamilyName'] = test_e['Name'].str.split(\",\",expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_e.FamilyName.value_counts() > 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 133 families with more than one member on board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 509 family name who does not have any clue about their cabin allocations. Cabin does not look significant feature This analysis is based on the assumption that people from the same family would share the same cabin information. The ticket number would be differnt but cabin information would definitely be same. Even if we try to fill in the missing data, we will still be missing 509 cabin information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_yes = list(train_e[train_e['Cabin'].isnull() == False]['FamilyName'])\n",
    "cabin_no = list(train_e[train_e['Cabin'].isnull() == True]['FamilyName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(cabin_no) - set(cabin_yes))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we plan to carry forward our analysis by dropping the cabin information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e.drop('Cabin', axis=1, inplace=True)\n",
    "test_e.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Survival by Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.FacetGrid(train_e, col = 'Survived')\n",
    "plot.map(plt.hist, 'Age', bins = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the age data we can say that although most of the passengers are in their 15-40 age range but those are the ones that didn't survive. Mostly the people who survived are in the age range of 0-10 and elderly people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(train_e, row='Pclass', col='Survived')\n",
    "grid.map(plt.hist, 'Age', bins =10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data visualization above, we can see that althougt Pclass 1 has the least amount of people those are the ones that survived the most. Pclass 3 has the most number of passengers but the survival rate is the lowest in proportion to the total number of passengers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(14,6))\n",
    "sns.countplot(data = train_e[train_e.Survived > 0], x = \"Pclass\",ax=ax1)\n",
    "ax1.set_title('Survived by Classes')\n",
    "sns.countplot(data = train_e[train_e.Survived == 0], x = \"Pclass\",ax=ax2)\n",
    "ax2.set_title('Not Survived By Classes')\n",
    "sns.countplot(data = train_e, x = \"Pclass\",ax=ax3)\n",
    "ax3.set_title('Passange By Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(14,6))\n",
    "sns.countplot(data = train_e[train_e.Survived > 0], x = \"Embarked\",ax=ax1)\n",
    "ax1.set_title('Survived by Embarked')\n",
    "sns.countplot(data = train_e[train_e.Survived == 0], x = \"Embarked\",ax=ax2)\n",
    "ax2.set_title('Not Survived By Embarked')\n",
    "sns.countplot(data = train_e, x = \"Embarked\",ax=ax3)\n",
    "ax3.set_title('Passange By Embarked')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the passengers embarked form port S, and those are the ones with the least survival rate. Port C had second highest number of passengers getting on board and those are the ones with the highest survival rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(14,6))\n",
    "sns.countplot(data = train_e[train_e.Survived > 0], x = \"Sex\", ax=ax1)\n",
    "ax1.set_title('Survived by Gender')\n",
    "sns.countplot(data = train_e[train_e.Survived == 0], x = \"Sex\", ax=ax2)\n",
    "ax2.set_title('Not Survived By gender')\n",
    "sns.countplot(data = train_e, x = \"Sex\",ax=ax3)\n",
    "ax3.set_title('Passange By Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data above we can see that although the population of the ship was male dominant but the survival rate was highly dependent on the gender. Females tend to have a higher survival rate as compared to the males. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(train_e, row='Sex', col='Survived')\n",
    "g = grid.map(plt.hist, 'Age', bins =10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data above we can see that females had a higher change of surival as compared to the males. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(train_e, row='Embarked', col='Survived')\n",
    "g =  grid.map(plt.hist, 'Age', bins =10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data visualization above tells us that although most of the people embarked from C they didn't have as much as high chance of survival as compared to Embarked class Q. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e[train_e['Embarked'].isnull() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check other members of Icard and Stone family because these two are the only family that are missing Embarked values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e[(train_e['FamilyName'].isin(['Icard','Stone']) == True) & (train_e['Embarked'].isnull() == False)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no other family members from Icard and Stone. Therefore, we decide to populate it with majority class. 'S' is the Embarked where most of the people boarded. Hence populatiing missing Embarked info with 'S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e['Embarked'].fillna('S',inplace = True)\n",
    "test_e['Embarked'].fillna('S',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(14,6))\n",
    "sns.countplot(data = train_e[train_e.Survived > 0], x = \"Embarked\",ax=ax1,hue=\"Sex\")\n",
    "ax1.set_title('Survived by Embarked')\n",
    "sns.countplot(data = train_e[train_e.Survived == 0], x = \"Embarked\",ax=ax2,hue=\"Sex\")\n",
    "ax2.set_title('Not Survived By Embarked')\n",
    "sns.countplot(data = train_e, x = \"Embarked\",ax=ax3,hue=\"Sex\")\n",
    "ax3.set_title('Passange By Embarked')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e['title'] = train_e['Name'].str.split(\",\",expand=True)[1].str.split(\" \",expand=True)[1]\n",
    "test_e['title'] = test['Name'].str.split(\",\",expand=True)[1].str.split(\" \",expand=True)[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "sns.set_style(\"white\")\n",
    "g =sns.countplot(data = train_e, x = \"title\")\n",
    "g.set_title('Popular Title')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different titles for the passengers on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_e.loc[test_e['title'].isin(['Capt.','Dr.','Rev.','Major.','Col.','the','Don.', 'Jonkheer.', 'Sir.', 'Lady.']), 'title'] = 'Spl.Prof'\n",
    "train_e.loc[train_e['title'].isin(['Capt.','Dr.','Rev.','Major.','Col.','the','Don.', 'Jonkheer.', 'Sir.', 'Lady.']), 'title'] = 'Spl.Prof'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging special titles into one title Special Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e.loc[train_e['title'].isin(['Ms.','Mlle.']), 'title'] = 'Miss.'\n",
    "train_e.loc[train_e['title'].isin(['Mme.']), 'title'] = 'Mrs.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_e.loc[test_e['title'].isin(['Ms.','Mlle.']), 'title'] = 'Miss.'\n",
    "test_e.loc[test_e['title'].isin(['Mme.']), 'title'] = 'Mrs.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "sns.set_style(\"white\")\n",
    "g =sns.countplot(data = train_e, x = \"title\")\n",
    "g.set_title('Popular Title')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the different titles have been grouped to form one or more new title therefore maximizing the inter class similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is harder to deal with categorical variables for the tiles, we will change them to numerical form.  We will also do the same for the sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e[train_e.Age.isnull()]['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_e[test_e.Age.isnull()]['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_mean_age = round(train_e[((train_e.title == 'Mr.') & ( train_e.Age != np.nan))]['Age'].mean())\n",
    "miss_mean_age = round(train_e[((train_e.title == 'Miss.') & ( train_e.Age != np.nan))]['Age'].mean())\n",
    "mrs_mean_age = round(train_e[((train_e.title == 'Mrs.') & ( train_e.Age != np.nan))]['Age'].mean())\n",
    "master_mean_age = round(train_e[((train_e.title == 'Master.') & ( train_e.Age != np.nan))]['Age'].mean())\n",
    "spl_mean_age = round(train_e[((train_e.title == 'Spl.Prof') & ( train_e.Age != np.nan))]['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mr_mean_age,miss_mean_age,mrs_mean_age,master_mean_age,spl_mean_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e['Age'] = train_e.apply(\n",
    "    lambda row: mr_mean_age if ((np.isnan(row['Age'])) & (row['title'] == 'Mr.')) else row['Age'], axis = 1)\n",
    "train_e['Age'] = train_e.apply(\n",
    "    lambda row: mrs_mean_age if ((np.isnan(row['Age'])) & (row['title'] == 'Mrs.')) else row['Age'], axis = 1)\n",
    "train_e['Age'] = train_e.apply(\n",
    "    lambda row: miss_mean_age if ((np.isnan(row['Age'])) & (row['title'] == 'Miss.')) else row['Age'], axis = 1)\n",
    "train_e['Age'] = train_e.apply(\n",
    "    lambda row: master_mean_age if ((np.isnan(row['Age'])) & (row['title'] == 'Master.')) else row['Age'], axis = 1)\n",
    "train_e['Age'] = train_e.apply(\n",
    "    lambda row: spl_mean_age if ((np.isnan(row['Age'])) & (row['title'] == 'Spl.Prof')) else row['Age'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_e['Age'] = test_e.apply(\n",
    "    lambda row: mr_mean_age if ((np.isnan(row['Age'])) & (row['title'] == 'Mr.')) else row['Age'], axis = 1)\n",
    "test_e['Age'] = test_e.apply(\n",
    "    lambda row: mrs_mean_age if ((np.isnan(row['Age'])) & (row['title'] == 'Mrs.')) else row['Age'], axis = 1)\n",
    "test_e['Age'] = test_e.apply(\n",
    "    lambda row: miss_mean_age if ((np.isnan(row['Age'])) & (row['title'] == 'Miss.')) else row['Age'], axis = 1)\n",
    "test_e['Age'] = test_e.apply(\n",
    "    lambda row: master_mean_age if ((np.isnan(row['Age'])) & (row['title'] == 'Master.')) else row['Age'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e.isnull().sum()\n",
    "train_z = train_e.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gender One Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = train_z.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e['Sex'] = [1 if x == 'male' else 0 for x in train_e['Sex']]\n",
    "test_e['Sex'] = [1 if x == 'male' else 0 for x in test_e['Sex']]\n",
    "#test_z['Sex'] = [1 if x == 'male' else 0 for x in test_e['Sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_e.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = {\"Spl.Prof\": 1, \"Mr.\": 2, \"Miss.\": 3, \"Mrs.\": 4, \"Master.\": 5}\n",
    "train_e['title'] = train_e['title'].map(title)\n",
    "\n",
    "test_e['title'] = test_e['title'].map(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embarked_label = {\"S\": 1, \"C\": 2, \"Q\": 3}\n",
    "train_e['Embarked'] = train_e['Embarked'].map(Embarked_label)\n",
    "\n",
    "test_e['Embarked'] = test_e['Embarked'].map(Embarked_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_e.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we decided to tackle the missing information of age is to fill in values with the median values of similar pclass and SibSp. We decided to choose those two features because from the coorelation table below we can see that Pclass and the SibSb have the largeset coorelation with the Age.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Name = train_e.pop('Name')\n",
    "train_ticket = train_e.pop('Ticket')\n",
    "train_FamilyName = train_e.pop('FamilyName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Name = test_e.pop('Name')\n",
    "test_ticket = test_e.pop('Ticket')\n",
    "test_FamilyName = test_e.pop('FamilyName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e['family'] = train_e['SibSp'] + train_e['Parch']\n",
    "test_e['family'] = test_e['SibSp'] + test_e['Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_e['family'] = test_e.apply(\n",
    "    lambda row: 1 if (row['family'] > 0 ) else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e['family'] = train_e.apply(\n",
    "    lambda row: 1 if (row['family'] > 0 ) else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_SibSp = train_e.pop('SibSp')\n",
    "train_Parch = train_e.pop('Parch')\n",
    "\n",
    "test_SibSp = test_e.pop('SibSp')\n",
    "test_Parch = test_e.pop('Parch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.array([0, 5, 12, 18, 21, 30, 40, 50, 60, 70, 80]),\n",
    "    index=['toddler','toddler','Young', 'Teen', 'Adult', '30s','40s','50s','60s','70s','80s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e['Age_Bucket'] = pd.cut(train_e['Age'],s)\n",
    "test_e['Age_Bucket'] = pd.cut(test_e['Age'],s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_e.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = pd.concat([train_e, pd.get_dummies(train_e['Pclass'], prefix='Pclass',drop_first=True)],axis = 1)\n",
    "train_e = pd.concat([train_e, pd.get_dummies(train_e['Embarked'], prefix='Embarked',drop_first=True)],axis = 1)\n",
    "train_e = pd.concat([train_e, pd.get_dummies(train_e['title'], prefix='title',drop_first=True)],axis = 1)\n",
    "train_e = pd.concat([train_e, pd.get_dummies(train_e['Age_Bucket'], prefix='Age_Bucket',drop_first=True)],axis = 1)\n",
    "train_e = pd.concat([train_e, pd.get_dummies(train_e['Sex'], prefix='Sex',drop_first=True)],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_e = pd.concat([test_e, pd.get_dummies(train_e['Pclass'], prefix='Pclass',drop_first=True)],axis = 1)\n",
    "test_e = pd.concat([test_e, pd.get_dummies(train_e['Embarked'], prefix='Embarked',drop_first=True)],axis = 1)\n",
    "test_e = pd.concat([test_e, pd.get_dummies(train_e['title'], prefix='title',drop_first=True)],axis = 1)\n",
    "test_e = pd.concat([test_e, pd.get_dummies(train_e['Age_Bucket'], prefix='Age_Bucket',drop_first=True)],axis = 1)\n",
    "test_e = pd.concat([test_e, pd.get_dummies(train_e['Sex'], prefix='Sex',drop_first=True)],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e.head(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e.pop('Pclass')\n",
    "train_e.pop('Age')\n",
    "train_e.pop('Sex')\n",
    "train_e.pop('Embarked')\n",
    "train_e.pop('title')\n",
    "Age_Bucket_train = train_e.pop('Age_Bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_e.pop('Pclass')\n",
    "test_e.pop('Age')\n",
    "test_e.pop('Sex')\n",
    "test_e.pop('Embarked')\n",
    "test_e.pop('title')\n",
    "Age_Bucket_test = test_e.pop('Age_Bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_e.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e.to_csv('clean_train.csv', sep=',')\n",
    "y = train_e.pop('Survived')\n",
    "X = train_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_summary(model_obj, model_name):\n",
    "    model_obj.fit(X_train, y_train)\n",
    "    print('-'*40)\n",
    "    print('Model : {}'.format(model_name))\n",
    "    print('-'*40)\n",
    "    print('Traing dataset score: {}'.format(model_obj.score(X_train, y_train)))\n",
    "    model_pred = model_obj.predict(X_test)\n",
    "    print('Test Data Metrics')\n",
    "    print ('Accuracy Score :\\t{:.4}'.format(accuracy_score(y_test,model_pred)))\n",
    "    print ('Recall Score :\\t\\t{:.4}'.format(recall_score(y_test,model_pred)))\n",
    "    print ('Precision Score :\\t{:.4}'.format(precision_score(y_test,model_pred)))\n",
    "    print(confusion_matrix(y_test, model_pred))\n",
    "    print(cross_val_score(model_obj, X, y, cv=5))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logit = LogisticRegression(solver='newton-cg', random_state=42, max_iter=1000,)\n",
    "rf = RandomForestClassifier(n_estimators=30, random_state=42)\n",
    "linear_svc = SVC(kernel='linear')\n",
    "rbf_svc = SVC(kernel='rbf')\n",
    "poly_svc = SVC(kernel='poly')\n",
    "gvc = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "model_summary(logit, 'LogisticRegression')\n",
    "model_summary(rf, 'Random Forest')\n",
    "model_summary(linear_svc, 'Linear SVM')\n",
    "model_summary(rbf_svc, 'Radial SVM')\n",
    "model_summary(poly_svc, 'Ploynominal SVM')\n",
    "model_summary(gvc, 'GradientBoostingClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('classifier' , LogisticRegression())])\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression()],\n",
    "    # 'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : [0.001,0.01,0.1,10,100,1000],\n",
    "    'classifier__solver' : ['liblinear' , 'newton-cg', 'sag' , 'lbfgs' ]}\n",
    "     #'max_iter': [100,300,500,700, 900, 1000]}   \n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = best_clf.predict(X_test)\n",
    "print('Test Data Metrics')\n",
    "print ('Accuracy Score :\\t{:.4}'.format(accuracy_score(y_test,model_pred)))\n",
    "print ('Recall Score :\\t\\t{:.4}'.format(recall_score(y_test,model_pred)))\n",
    "print ('Precision Score :\\t{:.4}'.format(precision_score(y_test,model_pred)))\n",
    "print(confusion_matrix(y_test, model_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e[train_e.columns[0:]].corr()['Age'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_matrix = np.zeros((8,3))\n",
    "\n",
    "# for i in range(0, 8):\n",
    "#     for j in range(0, 3):\n",
    "#         expected_value = train_e[(train_e['SibSp'] == i) & (train_e['Pclass'] == j+1)]['Age'].dropna()\n",
    "#         age = expected_value.median()\n",
    "#         age_matrix[i,j] = float(age/0.5 + 0.5 ) * 0.5\n",
    "    \n",
    "# for i in range(0, 8):\n",
    "#     for j in range(0, 3):\n",
    "#         train_e.loc[(train_e.Age.isnull()) & (train_e.SibSp == i) & (train_e.Pclass == j+1), 'Age'] = age_matrix[i,j]       \n",
    "# train_e['Age'] = train_e['Age'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_fare_median = test_e['Fare'].median()\n",
    "# test_e['Fare'].fillna(test_fare_median, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
